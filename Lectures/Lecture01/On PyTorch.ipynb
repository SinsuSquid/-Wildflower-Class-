{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e834e3f-2117-4497-8a9d-6c10b2c6f71d",
   "metadata": {},
   "source": [
    "# Lecture 01 : On PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d562a35-1a2e-426a-84e4-6392cb83dc3c",
   "metadata": {},
   "source": [
    "written by SinsuSquid (bgkang) on 00 November 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656734ff-af5f-4c1c-b651-a8c6429213bd",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e783b-9163-4920-850f-22bb94a9e1d9",
   "metadata": {},
   "source": [
    "저번 시간에는 perceptron, multi-layered perceptron (MLP)의 개념에 대해서만 간단하게 소개했고, 이를 PyTorch Framework를 통해 구현하는 것을 해봤었죠. 하지만 실상 까놓고 보면 우리가 한거라곤 Neural Network (NN) 구성을 위한 Layer 몇개 쌓아놓았던게 끝이였던 것 같아요. 오늘은 본격적으로 PyTorch Framework를 이용해서 model을 생성하고 training/validation & test cycle을 실제로 한번 구현해보는걸 목표로 진행할거에요. 우리가 model을 만든다고 하면 으레 진행하는 cycle이니까 이 과정에 대한 detail한 설명까지는 못해줄 것 같네요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb2d91-93ba-457a-8c90-edc3877e32c3",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0138b940-9c30-479a-a15d-d4f9e05d0db9",
   "metadata": {},
   "source": [
    "그냥 model에 냅다 들이받는 것 보다는 그래도 뭐라도 예측하고자 하는 target이 있으면 좋잖아요? 이번 시간에는 [AqSolDB](https://www.kaggle.com/datasets/sorkun/aqsoldb-a-curated-aqueous-solubility-dataset)에 있는 정보를 사용해서 compound의 solubility를 예측하는 regression model을 학습하고 검증해보도록 하겠습니다. (잊지 마요, 우린 사실 '화학과' 소속이란걸.) 그냥 파일 다운로드 받아도 무방하지만, 기왕 할거 간드러지게 해야 멋있잖아요? kaggle API를 사용해서 AqSolDB를 내 컴퓨터로 다운받아보도록 하겠습니다. (초기 setup은 귀찮으니까 수업할때 얘기할게요) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992eadfd-0739-4e6c-863e-e066fb7e511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets list -s AqSolDB # kaggle API를 이용한 dataset searching\n",
    "!kaggle datasets download -d sorkun/aqsoldb-a-curated-aqueous-solubility-dataset # dataset download\n",
    "!unzip -u ./aqsoldb-a-curated-aqueous-solubility-dataset.zip # 압축 풀기\n",
    "!rm ./aqsoldb-a-curated-aqueous-solubility-dataset.zip # 불필요한 zip 파일은 제거\n",
    "!ls # *.csv 파일이 생성되었나 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c389e40-01b9-4d72-a719-f0d012a47ca4",
   "metadata": {},
   "source": [
    "Dataset이 어떻게 생겨먹었나 한번 살펴볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb0a5a-479e-45da-873e-8e61212ccc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./curated-solubility-dataset.csv')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02c8e7b-8441-47d4-a086-9d6313815cd2",
   "metadata": {},
   "source": [
    "더 재미있는 방법으로 dataset을 augment를 시키는것도 가능하지만, 지금 당장은 그럴 의욕이 없네요. 주어진 dataset에서 필요한 부분만 추려서 정리를 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539a598-eb8b-45de-82f0-b2274c494f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,['Solubility', 'MolWt', 'MolLogP', 'MolMR', 'HeavyAtomCount', 'NumHAcceptors',\n",
    "               'NumHDonors', 'NumHeteroatoms', 'NumRotatableBonds', 'NumValenceElectrons',\n",
    "               'NumAromaticRings', 'NumSaturatedRings', 'NumAliphaticRings', 'RingCount', 'TPSA',\n",
    "               'LabuteASA', 'BalabanJ', 'BertzCT']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444d1d6-4d59-40c4-ac5c-01ea1bd07873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train, validation, test = np.split(df.sample(frac = 1, random_state = 42),\n",
    "                                   [int(0.8 * len(df)), int(0.9 * len(df))])\n",
    "print(f\"Train : {len(train)} | Validate : {len(validation)} | Test : {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab367e82-8e4a-47d5-85bd-c13780d59b17",
   "metadata": {},
   "source": [
    "데이터 불러와서 train, validate, test set으로 분리시키는 것 까지 완료했네요. 혹시 왜 이런 일을 하고있는지 이해가 가지 않는다면, 인공지능 기초를 YouTube를 통해 공부해오는게 좋을거에요! 여기까지 가르쳐줄 생각이 없거든요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c043d-e776-4666-9e0f-6477d5db891c",
   "metadata": {},
   "source": [
    "## Step 0 : Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53a572-fef1-4f45-8e2f-d19e8d13d3ce",
   "metadata": {},
   "source": [
    "Model을 정의하는 부분부터 시작해볼까요? 저번 시간에 간단하게만 언급했지만 PyTorch의 장점은 \"Pythonic\"한 방식으로 model을 구성할 수 있다는 점이죠. 강요하진 않겠지만 저는 \"Pythonic\"하게 내 방식으로 진행할터이니 알아서 잘 따라 오던가 하세요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3401510-b120-4dc8-90ad-35d07db1640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class LinearReLU(torch.nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_size, self.out_size = in_size, out_size\n",
    "        \n",
    "        self.linear = torch.nn.Linear(self.in_size, self.out_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return self.relu(x)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, in_size, out_size, hidden_size, num_hidden_layer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size, self.out_size, self.hidden_size = in_size, out_size, hidden_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "\n",
    "\n",
    "        self.in_layer = LinearReLU(self.in_size, self.hidden_size)\n",
    "        self.hidden_layer = torch.nn.Sequential(\n",
    "            *[LinearReLU(self.hidden_size, self.hidden_size) for _ in range(num_hidden_layer)]\n",
    "        )\n",
    "        self.out_layer = torch.nn.Linear(self.hidden_size, self.out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.in_layer(x)\n",
    "        for hl in self.hidden_layer:\n",
    "            x = hl(x)\n",
    "        return self.out_layer(x)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.in_layer.reset_parameters()\n",
    "        for hl in self.hidden_layer:\n",
    "            hl.reset_parameters()\n",
    "        self.out_layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c966d44-2d3f-4247-b869-64a0e930497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(in_size = 17, out_size = 1, hidden_size = 50, num_hidden_layer = 3)\n",
    "model.reset_parameters()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d33a35-56c9-4602-af14-aaceec0b94d1",
   "metadata": {},
   "source": [
    "## Step 1 : How to use `DataSet` & `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1422455-363e-492c-8a1f-1ea2f0eb8a85",
   "metadata": {},
   "source": [
    "PyTorch 쓰는 이유중에 하나는 강력한 `DataSet`과 `DataLoader`의 기능이죠. 이쯤에서 Python의 `Iterator`라는 개념을 알고 계시면 좋겠네요. DataLoader를 잘 구성하면 epoch마다 model에 batch를 넣어주는 과정을 `Iterator`를 이용해 단순화시킬 수 있습니다. 사용법도 매우 쉬우니까 `DataLoader`의 개념을 잘 이해해 두었다가, 나중에 `torch_geometric`에 대한 설명을 할 때 활용했으면 좋겠어요. (네, 잘 기억해놓으란 뜻입니다.)\n",
    "<br>\\\n",
    "이제 Custom `Dataset`을 구성하는 부분부터 시작해볼까요? 이 부분은 personal preference가 많이 들어갈 것 같은데, 제 입맛대로 한번 해보도록 할게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4473e-6b16-4b2f-81b3-2ad2f18aea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        self.y = torch.tensor(self.df.iloc[:,0].values) # 'Solubility' column\n",
    "        self.x = torch.tensor(self.df.iloc[:,1:].values) # anything other than 'Solubility' column\n",
    "\n",
    "        self.y = self.y.float().reshape(-1, 1) # Type Casting & Formatting\n",
    "        self.x = self.x.float().reshape(-1, 17)\n",
    "\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx,:], self.y[idx]\n",
    "\n",
    "train_dataset = CustomDataset(train)\n",
    "validation_dataset = CustomDataset(validation)\n",
    "test_dataset = CustomDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc24d52-41cc-4536-9ec6-9e189fdef610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(train_dataset.y)\n",
    "print(train_dataset[42]) # 이렇게 쓰면 돼요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9bce41-380e-4c5d-9877-50b2fa14929b",
   "metadata": {},
   "source": [
    "다음은 `Dataset`으로부터 `DataLoader`를 구성해보도록 할게요. `Dataset`만 멀쩡하게 구성되어있으면 어렵지 않습니다. 오히려 이번에는 `DataLoader`를 어떻게 사용하는지를 조금 더 집중해서 살펴보아요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feee241-d091-4a0c-a979-81c23333c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size에 대한 개념은 알아서 기억해오세요~\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 256)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size = 256)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c0bc4-7352-4d5b-8239-ce7fd45f0f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_loader:\n",
    "    print(x.shape, y.shape) # DataLoader를 쓰면 알아서 batch가 만들어진다는 사실~!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ce970-c5c2-4cfd-8d57-7475c30938dc",
   "metadata": {},
   "source": [
    "batch를 `Iterator`의 형태로 사용할 수 있다는 건 크나큰 장점이죠. (왜 장점인지 모르겠다고요? 조금만 기다리면 `torch_geometric`에서 알 수 있어요)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307eb668-9b0a-4ef2-81e4-4016e2c9dcab",
   "metadata": {},
   "source": [
    "## Step 2 : Define training functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad3e11-84f0-4deb-8149-88adcfaa7733",
   "metadata": {},
   "source": [
    "흔히 모델 학습을 할 때 \"예측값 계산 -> 가중치 업데이트\"를 반복하게 되죠. (네, 알아서 찾아오세요.)\n",
    "<br>\\\n",
    "PyTorch를 사용하는 사람들은 각 과정을 function으로 정의하여 사용한답니다. (저는 별도의 `Training` Object를 만드는걸 선호하는 편인데, 오늘은 대세에 따라보기로 하죠.)\n",
    "<br>\\\n",
    "지금부터는 model 학습 과정에서 실제로 어떤 일들이 일어나는지를 정의하는 부분인데, 이 과정을 제가 하나하나 설명할 수는 없습니다. (누가 돈이라도 주면 몰라요 히히) 그러니까 \"이런게 왜 필요하지?\" 라고 생각이 든다면 이 Lecture를 볼게 아니라 당장 가서 다른 책이나 YouTube를 보는게 맞다고 생각해요. 제가 여기서 해줄 수 있는건 code에서 각 문장이 어떤 과정을 의미하는지만을 알려줄 수 있을 뿐이고, 각각의 procedure들은 꼭 공부를 해오든 찾아오든 할 수 있길 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee26244-0231-49af-b1f4-0fcd8c0f7d3b",
   "metadata": {},
   "source": [
    "먼저 `optimizer`나 `criterion` (loss function을 이렇게 부르시더라고요) 등에 대한 정의가 필요한데, 이런 개념들도 스스로 공부를 해오셔야 할 듯 합니다. 이번 Lecture는 PyTorch의 사용법을 익히는게 목표니까, 소위 '국룰'이라 불리는 설정으로 초기화를 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e09efb-bc44-46ca-97da-bd91772a0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer가 뭔지는 여기서 못 알려줘요!\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1E-3)\n",
    "# Regression 문제니까 MSE를 사용해요 - 이해 안되면 공부해와잇!\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584a5c4-0edf-45c2-9fba-e59d01bc9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch별 training 단계\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train() # model을 train 모드로 설정 - 가중치 업데이트 활성화\n",
    "\n",
    "    tot_loss = 0.0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad() # Optimizer를 (일종의) 초기화\n",
    "        \n",
    "        out = model(x) # 출력값 계산\n",
    "        loss = criterion(out, y) # loss 계산\n",
    "        loss.backward() # 가중치 계산 - 이게 code 한줄로 구현이 가능하다니!!\n",
    "        \n",
    "        # (여기서 감동하면 됩니다.)\n",
    "        \n",
    "        optimizer.step() # 가중치 update\n",
    "\n",
    "        tot_loss += loss.item() # Trainng Loss 계산을 위하여\n",
    "\n",
    "    return tot_loss / len(loader) # averaged 된 loss값을 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8baa1c7-7a6c-4233-ba3e-6d3770594bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch별 validation 단계\n",
    "\n",
    "def validation(model, loader):\n",
    "    model.eval() # model을 eval 모드로 설정 - 가중치 업데이트 비활성화\n",
    "\n",
    "    tot_loss = 0.0\n",
    "\n",
    "    with torch.no_grad(): # gradient 계산 안하겠다 - 그만큼 속도를 아끼겠죠?\n",
    "        for x, y in loader:\n",
    "            out = model(x) # 출력값 계산\n",
    "            loss = criterion(out, y) # loss 계산\n",
    "    \n",
    "            tot_loss += loss.item() # Validation Loss 계산을 위하여\n",
    "    \n",
    "    return tot_loss / len(loader) # averaged 된 loss값을 return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cf29b-0cea-4f67-881f-1a513cd2101d",
   "metadata": {},
   "source": [
    "`validation`에서 확인해야 할 부분은, `loss.backward()`랑 `optimizer`를 호출한적이 없다는 점이에요. 사실 `validation`함수가 수행하는 목적을 생각하면 당연한 일이겠지요? (네, 알아서 이해 해오세요.)\n",
    "<br>\\\n",
    "마지막으로, epoch하나당 수행해야 할 일을 `run`이란 이름의 함수로 정의해보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14254ebd-82be-487b-9922-77bddd6220f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loss = []; val_loss = [] # Loss Curve도 그려봐야하니까~\n",
    "\n",
    "def run(epochs): # epoch 수를 이 부분에서 받아오도록 하죠\n",
    "    for e in range(epochs):\n",
    "        trn_loss.append(train(model, train_loader))\n",
    "        val_loss.append(validation(model, validation_loader))\n",
    "\n",
    "        print(f\"Epoch : {e:05d} | Trn. Loss : {trn_loss[-1]:.3f} | Val. Loss : {val_loss[-1]:.3f}\")\n",
    "\n",
    "    print(\"Training Complete! >:D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686fdb99-7c86-4bc8-b40e-807f2f9eb358",
   "metadata": {},
   "source": [
    "## Step 3 : Roll the dice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b3a36-bf36-4a24-bf04-88f922b1d418",
   "metadata": {},
   "source": [
    "여기까지 했으면 이제 뭐 하겠어요, 잘 돌아가나 함 봐야지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071099f1-2db3-456e-a3c2-8b9d7728da93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run(100) # 간단하게 100번만?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31645e8a-c693-4910-b74b-0cfee5b522de",
   "metadata": {},
   "source": [
    "## Step 4 : Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3263e-d57d-4da7-b925-1b0b050237fc",
   "metadata": {},
   "source": [
    "다행히 training process까지 무사하게 진행했으면, 이제 실제로 학습된 model의 performance가 어떻게 되는지 체크해봐야겠죠. `test` 혹은 `eval`이란 별도의 함수를 작성하시는 분들도 있지만, (네, 저요.) 하는 짓은 아래 code에서 크게 다르지 않으니까 입맛대로 수정할 수 있을거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d1630-0086-4931-9e15-2a0c8b7a010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    pred = []; true = []\n",
    "\n",
    "    for x, y in test_loader:\n",
    "        # torch.tensor보다 numpy.ndarray가 다루기 편하니까 변환해서 저장하도록 할게요.\n",
    "        out = model(x)\n",
    "        test_loss += criterion(out, y)\n",
    "        pred.append(out.numpy())\n",
    "        true.append(y.numpy())\n",
    "\n",
    "test_loss = test_loss.item() / len(test_loader)\n",
    "pred = np.concatenate(pred).flatten()\n",
    "true = np.concatenate(true).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb58bd-e95b-47fb-8b80-9d5a4558ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss # 이것만으로는 학습이 잘 된건지 모르겠잖아!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6d811-4755-436a-8af0-2c48ff9288a6",
   "metadata": {},
   "source": [
    "model 성능을 더 확인해보기에 앞서, 최소한 학습은 되고 있는가 loss curve를 그려보도록 하죠. (혹시 loss curve가 뭔지 잘 모르겠으면... 알죠?)\n",
    "<br><br>\n",
    "이건 여담인데, 저도 그림 그리는 센스가 별로 좋은 편이 아니기 때문에 더 예쁜 그림을 그리고싶으면 다른 자료를 잘 공부하는게 좋아요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce136a8e-04c9-43d7-89de-07c666d089ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8, 8), dpi = 200)\n",
    "\n",
    "ax.set_xlabel(\"Epoch\", fontsize = 15)\n",
    "ax.set_ylabel(\"Loss\", fontsize = 15)\n",
    "ax.set_title(\"Loss Curve\", fontsize = 20)\n",
    "\n",
    "ax.plot(range(100), trn_loss, linewidth = 3, label = 'Training Loss')\n",
    "ax.plot(range(100), val_loss, linewidth = 3, label = 'Validation Loss')\n",
    "ax.hlines(test_loss, 0, 100, linestyle = '--', color = 'k', label = 'Test Loss')\n",
    "\n",
    "ax.legend(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c215f-53b2-4bf2-8a8e-3f5f892c5d07",
   "metadata": {},
   "source": [
    "썩 마음에 드는 결과는 아니지만, 우리의 첫 성과잖아요? (보잘 것 없고... 귀여워...)\n",
    "<br><br>\n",
    "다음엔 parity plot을 그려보도록 하죠. (이젠 무슨 말 할지 알죠?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ba63f-3fc6-4f8e-aab0-48170b47b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 8), dpi = 200)\n",
    "\n",
    "ax.set_xlabel(\"True Value\", fontsize = 15)\n",
    "ax.set_ylabel(\"Predicted Value\", fontsize = 15)\n",
    "ax.set_title(\"Solubility\", fontsize = 20)\n",
    "\n",
    "ax.plot(true, true, linestyle = '--', color = 'k', linewidth = 3)\n",
    "ax.plot(true, pred, linestyle = 'None', marker = 'o', markersize = 7, alpha = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d954c-89e8-4183-b88c-6eccb3b58b09",
   "metadata": {},
   "source": [
    "이렇게 그림만 그려놓으면 정량적인 비교가 어렵잖아요? Error 지표 몇개정도 계산해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf20802-d2c1-45af-a268-1357db3acf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "mae = np.abs(true - pred).mean()\n",
    "\n",
    "# Root Mean Squared Error\n",
    "rmse = np.sqrt(np.power(true - pred, 2).mean())\n",
    "\n",
    "# Mean Absolute Percent Error\n",
    "mape = np.abs((true - pred) / true * 100).mean()\n",
    "\n",
    "# R2 - 귀찮으니까 ㅎㅎ\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(true, pred)\n",
    "\n",
    "print(f\"MAE : {mae:.3f} | RMSE : {rmse:.3f} | MAPE : {mape:.3f} | R2 : {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca72f4-7348-4db4-82ae-9dfbeb171863",
   "metadata": {},
   "source": [
    "여기까지 왔으면 일반적으로 수행하는 training / validation / test \"Cycle\"을 한번 수행해본게 되겠네요. (네, \"Cycle\"이요. 다시 말해, 이걸 밥먹듯이 해야한다는 의미죠.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891da73a-cc19-430e-a7f2-3334aa98fbf1",
   "metadata": {},
   "source": [
    "## Step 4.5 : Model Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2a39a-3d3a-405c-92c1-2405bde1b11a",
   "metadata": {},
   "source": [
    "물론 지금까지 학습된 model은 작고 귀여운 감자에 불과하지만, 그래도 기념이니까 한번 저장을 해보도록 할게요. PyTorch에서는 model의 `state_dict`를 저장하는것을 '권장'하는데, 이는 model의 구조까지는 저장하지 않고 각 layer의 learnable(trainable) parameter만을 저장한다고 생각하면 될 것 같아요. 다시 말해, 저장한 model을 다시 불러 쓰기 위해서는 저장한 model과 동일한 형태 - size 등 - 를 가져야 한다는 뜻입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679dc01-d77b-4dc6-8379-659fd92a189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./my_little_cute_first_potato.model\"\n",
    "torch.save(model.state_dict(), PATH) # 나의 작고 귀여운 감자가 저장되었어요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a44302-5ce1-426c-9710-bb4079b28894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model과 new_model은 완벽하게 동일한 구조여야 해요!\n",
    "new_model = MyModel(in_size = 17, out_size = 1, hidden_size = 50, num_hidden_layer = 3)\n",
    "new_model.load_state_dict(torch.load(PATH, weights_only = True))\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc77c44-f65f-4bbc-a0e5-1abb3adc20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Check!\n",
    "print(\"Old Potato : \", model.in_layer.linear.weight[0])\n",
    "print(\"New Potato : \", new_model.in_layer.linear.weight[0]) # Yay! Another cute little potato!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40750f1d-91a6-4926-9a76-b1adf3eca04e",
   "metadata": {},
   "source": [
    "## Step 5 : Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3488d85-38dc-4ced-8f86-e84c56a0aee6",
   "metadata": {},
   "source": [
    "원래 여기까지 계산을 다 완료했으면 다음 단계는 실제 model의 성능을 비교하는 일이 될거에요. 아쉽게도 [AqSolDB의 kaggle 페이지](https://www.kaggle.com/datasets/sorkun/aqsoldb-a-curated-aqueous-solubility-dataset/data)를 확인해보니 성능을 비교할만한 다른 model들이 아직 업로드되지가 않았네요. 하지만 실제 model 개발은 이 단계부터 시작해야해요. 내가 만든 model의 성능은 기존의 model에 비해 어떤 정도인지, 정확도를 높이기 위해서는 어떤 방식으로 개선을 해야하는지 - 새로운 개념? 효율적인 hyperparamter optimization? 등을 고려하며 내 model을 좀더 멋지게 만들어나갈 전략에 대해 생각해보아야겠죠. 뭐, 오늘은 작교 귀여운 model을 처음 만들어본거니 이쯤에서 수고했어요 짝짝짝 한 후 마무리하도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca1c52-a36c-4d39-81dd-f8dc34ff950f",
   "metadata": {},
   "source": [
    "## Outtro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ff25e-75f4-4a34-b442-a7f70f3980f2",
   "metadata": {},
   "source": [
    "저번 시간부터 밥먹듯이 하는 말이 있죠? 모르는 부분 있으면 알아서 공부 해오라고. 나도 다 아는 내용이고 알려줄 수도 있어요. 내가 여기까지 해 줄 필요가 없어서 (그리고 귀찮아서...) 안하는거에요. 시작하기 전부터 경고 많이 했었지만 들꽃반 만만하게 가르칠 생각 없어요 ㅎㅎ. 대신 언제든지 중도하차는 기쁜 마음으로 허락할게요, 진짜! 마음의 상처 하나도 없이!\n",
    "<br>\n",
    "이번 시간 내용이 정리되지 않는다면 다음시간 (아마 `torch_geometric`이겠죠?) 수업을 듣는 이유가 하나도 없을거라고 미리 겁을 좀 더 줄게요. (당근은 안주고 채찍만 계속 주니, 나쁜 기수로군요.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
